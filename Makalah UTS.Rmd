---
title: "Makalah DMKM"
author: "Desi Kristiyani/ 221810237/ 09/3SD2"
date: "11/3/2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
**Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:**
1 school - student's school (binary: "GP" - Gabriel Pereira or "MS" - Mousinho da Silveira)
2 sex - student's sex (binary: "F" - female or "M" - male)
3 age - student's age (numeric: from 15 to 22)
4 address - student's home address type (binary: "U" - urban or "R" - rural)
5 famsize - family size (binary: "LE3" - less or equal to 3 or "GT3" - greater than 3)
6 Pstatus - parent's cohabitation status (binary: "T" - living together or "A" - apart)
7 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
8 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)
9 Mjob - mother's job (nominal: "teacher", "health" care related, civil "services" (e.g. administrative or police), "at_home" or "other")
10 Fjob - father's job (nominal: "teacher", "health" care related, civil "services" (e.g. administrative or police), "at_home" or "other")
11 reason - reason to choose this school (nominal: close to "home", school "reputation", "course" preference or "other")
12 guardian - student's guardian (nominal: "mother", "father" or "other")
13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)
14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)
15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)
16 schoolsup - extra educational support (binary: yes or no)
17 famsup - family educational support (binary: yes or no)
18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)
19 activities - extra-curricular activities (binary: yes or no)
20 nursery - attended nursery school (binary: yes or no)
21 higher - wants to take higher education (binary: yes or no)
22 internet - Internet access at home (binary: yes or no)
23 romantic - with a romantic relationship (binary: yes or no)
24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)
25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)
26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)
27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)
28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)
29 health - current health status (numeric: from 1 - very bad to 5 - very good)
30 absences - number of school absences (numeric: from 0 to 93)

**these grades are related with the course subject, Math or Portuguese:**
31 G1 - first period grade (numeric: from 0 to 20)
31 G2 - second period grade (numeric: from 0 to 20)
32 G3 - final grade (numeric: from 0 to 20, output target)

Additional note: there are several (382) students that belong to both datasets . 
These students can be identified by searching for identical attributes
that characterize each student, as shown in the annexed R file.

# Membaca data
```{r,comment="",echo=TRUE}
studentMat<-read.csv("D:/Sem 5/DMKM/Arie Wahyu W/TUGAS/new/student-matNew.csv",sep=";",header=TRUE)
str(studentMat) #395 pelajar dengan 33 faktor
#View(studentMat)
```

# Preprocessing
```{r,comment="",echo=TRUE}
#Mengubah tipe data yang tidak sesuai
newStudentMat1<-studentMat[,c(1:2,4:12,15:23)]
newStudentMat2<-studentMat[,c(3,13:14,24:33)]
#semua tipe data chr harus diubah ke dalam bentuk factor supaya dapat dikenali sebagia kategori
for(i in names(newStudentMat1)) {
  newStudentMat1[,i]= as.factor(newStudentMat1[,i])
}
for(i in names(newStudentMat2)) {
  newStudentMat2[,i]= as.numeric(newStudentMat2[,i])
}

studentMat<-cbind(newStudentMat1,newStudentMat2)

studentMat<-studentMat[,-c(1:11,13:20)] #Menyisihkan data yang tidak diolah
str(studentMat) #memiliki 1 variabel target yaitu failures dan 13 variabel faktor/prediktor

#Cek ada tidaknya missing value
library(visdat)  # visualisasi dari missing value
vis_miss(studentMat) #ternyata tidak ada missing value nya dan data sudah siap dilakukan pengolahan

#Normalisasi dengan **Min-Max Scaling**. Normalisasi dilakukan pada semua atribut yang bertipe numerik *kecuali target class*. Hal ini dimaksudkan karena satuan antar variabel berbeda maka perlu dilakukan scaling.
normalisasi<- function(r){
  return((r-min(r))/(max(r)-min(r)))
}

for(i in colnames(studentMat[-1])){           #kecuali target class nya yaitu failures
    studentMat[ ,i]=normalisasi(studentMat[ ,i])
}
head(studentMat)
```

# SVM
```{r,comment="",echo=TRUE}
library(tidyverse) #untuk plotting dan mengolah variabel
library(e1071)     #untuk melakukan pemodelan SVM
library(caret)

modelSVM <- svm(failures~., data=studentMat)
summary(modelSVM)
pred <- predict(modelSVM, studentMat)
confusionMatrix(table(Predicted = pred, Actual=studentMat$failures))

set.seed(123)
ngulikngulik <- tune(svm, failures~., data=studentMat,
                     ranges = list(epsilon = seq(0,1,0.1),
                     cost = 2^(2:9)))
plot(ngulikngulik)
summary(ngulikngulik)
```
Memiliki akurasi dari model sebesar 0.9291. Didapat model terbaik dengan epsilon 0 dan cost 16





# ANN
```{r,comment="",echo=TRUE}
library(neuralnet)
library(caret)
#model neural net
#n<-names(training_set)
#f<-as.formula(paste("failures~",paste(n[!n %in% "failures"],collapse = "+")))
nn<-neuralnet(f,data=training_set,hidden = c(5,3),linear.output = T)
#plot(nn)

set.seed(666)
sampel <- sample(2,nrow(studentMat),replace = T, prob = c(0.8,0.2))
data_train <- studentMat[sampel==1, ]
data_test <- studentMat[sampel==2, ]
print(paste("Jumlah train data :", nrow(data_train)))
print(paste("Jumlah test data :", nrow(data_test)))


set.seed(223)
#model dengan 1 hidden layer dan hidden node
modelnn<-neuralnet(failures~., data=data_train,
                   hidden = 1,
                   err.fct = "ce",
                   linear.output = F)
plot(modelnn)


#model dengan 1 hidden layer dan 5 hidden node
modelnn5<-neuralnet(failures~., data=data_train,
                    hidden = 5,
                    err.fct = "ce",
                    linear.output = F)
plot(modelnn5)


#model dengan 2 hidden layer, masing masing 2 hidden node dan 1 hidden node
modelnn21<-neuralnet(failures~., data=data_train,
                     hidden = c(2,1),
                     err.fct = "ce",
                     linear.output = F)
plot(modelnn21)



# 1 hidden layer dan hidden node
prediksi <- compute(modelnn, data_test[ ,-1])
pred <- ifelse(prediksi$net.result>0.5, 1, 0)
head(pred)
#5 hidden node
prediksi5 <- compute(modelnn5, data_test[ ,-1])
pred5 <- ifelse(prediksi5$net.result>0.5, 1, 0)
head(pred5)
#2 hidden layer, 2 hidden node dan 1 hidden node
prediksi21 <- compute(modelnn21, data_test[ ,-1])
pred21 <- ifelse(prediksi21$net.result>0.5, 1, 0)
head(pred21)




confusionMatrix(table(nn, data_test$failures))
confusionMatrix(table(pred5, data_test$failures))
confusionMatrix(table(pred21, data_test$failures))

```
Memiliki akurasi dari model sebesar 0.9165385 ======= 0.9231    dengan size=1









# KNN
```{r,comment="",echo=TRUE}
library(caret)
library(klaR)

#Split dataset
index<-createDataPartition(studentMat$failures,p=0.8,list=FALSE) #membuat 80% untuk training set dan 20% untuk testing set
data_train<-studentMat[index,]
data_test<-studentMat[-index,]

#melakukan k-fold cross validation yaitu membagi data secara random menjadi beberapa bagian kemudian dilakukan training terhadap classifier dengan menggunakan beberapa bagian testing dilakukan dengan bagian lain 
#training <- trainControl(method = "cv",number = 10)

#pemodelan dengan data training
#model1<-train(failures~.,data=data_train,trControl=training,method="knn") #menggunakan dataset dengan tipe data numerik
#print(model1)

#prediksi dengan data testing
#prediksi1<-predict(model1,newdata=data_test)

#melihat akurasi dari model yang dibentuk
#confusionMatrix(table(prediksi1, data_test$failures)) #dari testing set



################################
library(class)

prediksi <- knn(data_train,data_test, data_train$failures ,k=9) #karena k optimal adalah 9
prediksi
confusionMatrix(table(prediksi, data_test$failures)) #dari testing set

```
Memiliki akurasi dari sebesar 0.9114103 ====== 0.9231 dengan k=7





########################
#Pengujian 3 macam Kernel
#library(e1071)
#modela<-svm(failures~.,data=data_train,kernel="radial")
#modelb<-svm(failures~.,data=data_train,kernel="linear")
#modelc<-svm(failures~.,data=data_train,kernel="sigmoid",gamma=0.05,coef0=0.4)

#pred1<-predict(modela,data_test)
#pred2<-predict(modelb,data_test)
#pred3<-predict(modelc,data_test)

#confusionMatrix(pred1,data_test$failures)
#confusionMatrix(pred2,data_test$failures)
#confusionMatrix(pred3,data_test$failures)























